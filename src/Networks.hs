{- |
Module      : $Header$
Description : Definition of 'Network' and related functions
Copyright   : (c) Denis Torgunov, 2015-2016
License     : MIT

Maintainer  : dtorgunov@leafonthewind.net
Stability   : experimental
Portability : portable (depends on Gtk2Hs)

This module provides the definitions of the 'Network' data type, and all related data types and functions, such as those dealing with construction of a network, as well as those that use the network for classification.

At the moment the hyperplane distance parameter is assumed to be 0.5.
-}
module Networks (
                 Network
                , emptyNet
                , isEmptyNet
                , hyperplane
                , intersectNet
                , unionNet
                , makeNetwork
                , runNetwork
                , perceptronNetwork
                , countPerceptrons
                , classify
                ) where

import Types
import Data.Tree

-- | A "network descpriton": this shows the topology of the network, and can be used to trace how it was
-- constructed. It represents a network on a "conceptual" level, as seen by the algorithm.
data NetworkDesc
    -- | An 'Empty' network is used as a starting point of some recursions, as well as a "catch-all" value to
    -- be returned in case of errors. It is not meant to be evaluated in input data, and doing so
    -- raises an error.
    = Empty
    -- | A 'Hyperplane' network is simply a single separating hyperplain that correctly classifies a pair of points.
    -- This hyperplane is orthogonal to a line connecting the two points. 
    | Hyperplane { plusPoint :: Input -- ^ The point classified as +1 by this hyperplane
                 , minusPoint :: Input -- ^ The point classified as -1 by this hyperplane
                 , c :: Double -- ^ A parameter that shows how close/far the hyperplane is from the +1 point
                 }
    -- | Represents a union of 2 networks
    | Union NetworkDesc NetworkDesc
    -- | Represents an intersection of 2 networks
    | Intersection NetworkDesc NetworkDesc
      deriving (Show, Eq) -- Implement show explicitly?

-- | A "network function" is a simple function from 'Input' to 'Classification' that can be used
-- to classify any given input vector.
type NetworkFunction = Input -> Classification

-- | A network combines a network function and a description of the underlying network.
-- This is generated by the 'makeNetwork' function.
data Network = Network { f :: NetworkFunction
                       , net :: NetworkDesc
                       }

-- At the moment, we "show" a network by showing its description
instance Show Network where
    show n = show $ net n

-- | A sign activation function.
sign :: ActivationFunction
sign = signum

-- | Constructs an empty network
emptyNet :: Network
emptyNet = makeNetwork Empty

-- | Checks whether a network is empty
isEmptyNet :: Network -> Bool
isEmptyNet n = (net n) == Empty

-- | Constructs a network to separate two given points by a single hyperplane
hyperplane :: Input -> Input -> Double -> Network
hyperplane plusOne minusOne c = makeNetwork $ Hyperplane plusOne minusOne c

-- | Constructs an intersection of two networks
intersectNet :: Network -> Network -> Network
n1 `intersectNet` n2
   | isEmptyNet n1 = n2
   | isEmptyNet n2 = n1
   | otherwise = makeNetwork $ Intersection (net n1) (net n2)

-- | Constructs a union of two networks
unionNet :: Network -> Network -> Network
n1 `unionNet` n2 
   | isEmptyNet n1 = n2
   | isEmptyNet n2 = n1
   | otherwise = makeNetwork $ Union (net n1) (net n2)

-- | A separating hyperplane function
sepFunct :: Input -- ^ Point to be classified as -1
         -> Input -- ^ Point to be classified as +1
         -> Double -- ^ The position parameter
         -> (Input -> Double) -- ^ Returns a function that can then be passed to the activation function
sepFunct u v c = \x -> (x <.> w) - l
    where
      w = zipWith (-) v u
      l = c * (squaredNorm w) - (squaredNorm u) + (u <.> v)

-- | Generate a network function based on the network description
networkFunction :: NetworkDesc -> NetworkFunction
networkFunction Empty = \_ -> 0
networkFunction (Hyperplane plusOne minusOne c) = sign . sepFunct minusOne plusOne c
networkFunction (Union n1 n2) = \xs -> sign $ (n1' xs) + (n2' xs) + 0.5
    where
      n1' = networkFunction n1
      n2' = networkFunction n2
networkFunction (Intersection n1 n2) = \xs -> sign $ (n1' xs) + (n2' xs) - 0.5
    where
      n1' = networkFunction n1
      n2' = networkFunction n2

-- | Create a network based on the description of its topology
makeNetwork :: NetworkDesc -> Network
makeNetwork n = Network (networkFunction n) n

-- | Classify an 'Input' vector by the given 'Network'
runNetwork :: Network -> Input -> Classification
runNetwork n xs = (f n) xs

-- | Compute the squared norm of a given vector
squaredNorm :: [Double] -> Double
squaredNorm = sum . map (^2)

-- | Compute the dot (scalar) product of two vectors
(<.>) :: [Double] -> [Double] -> Double
a <.> b = sum $ zipWith (*) a b

-- | Generate a perceptron (represented as a its 'Weights') corresponding to a given 'Network'.
-- Note that this does NOT recursively traverse the network, it only returns the perceptron
-- corresponding to the top-most classifier
generatePerceptron :: Network -> Weights
generatePerceptron = generatePerceptron' . net

-- | An equivalent of 'generatePerceptron', but operates on 'NetworkDesc' instead of 'Network'
generatePerceptron' :: NetworkDesc -> Weights
generatePerceptron' Empty = error "Cannot generate an empty network perceptron"
generatePerceptron' (Union _ _) = [1.0, 1.0, 0.5]
generatePerceptron' (Intersection _ _) = [1.0, 1.0, (-0.5)]
generatePerceptron' (Hyperplane plusOne minusOne c) = ws ++ [b]
    where
      ws = zipWith (-) plusOne minusOne
      b = (squaredNorm minusOne) - (minusOne <.> plusOne) - c * (squaredNorm ws)

-- | Used as the 'unfold' function when constructing a tree (i.e. 'PerceptronNetwork')
-- from a 'Network'.
ndescUnfolder :: NetworkDesc -> (Weights, [NetworkDesc])
ndescUnfolder Empty = error "Cannot generate a tree with empty nets"
ndescUnfolder h@(Hyperplane _ _ _) = (generatePerceptron' h, [])
ndescUnfolder u@(Union n1 n2) = (generatePerceptron' u, [n1, n2])
ndescUnfolder i@(Intersection n1 n2) = (generatePerceptron' i, [n1, n2])

-- | Convert a 'Network' to 'PerceptronNetwork', going from a description of the way
-- the network was constructed to a tree of perceptron weights
perceptronNetwork :: Network -> PerceptronNetwork
perceptronNetwork = unfoldTree ndescUnfolder . net

-- | Checks if a 'Tree' represents a leaf (i.e. has no children)
leaf :: Tree a -> Bool
leaf tree = null $ subForest tree

-- | Adds a value as a sub-node for every leaf in the tree
addToLeaves :: a -> Tree a -> Tree a
addToLeaves val tree
    | leaf tree = Node { rootLabel = rootLabel tree
                       , subForest = [Node { rootLabel = val
                                           , subForest = []
                                           }]
                       }
    | otherwise = Node { rootLabel = rootLabel tree
                       , subForest = map (addToLeaves val) (subForest tree)
                       }

-- | Classify an 'Input' using a 'PerceptronNetwork'. Should return the same result as 'runNetwork'.
classify :: Input -> PerceptronNetwork -> Classification
classify x pn = reduceNetwork augmentedTree
     where
       augmentedTree = addToLeaves (x ++ [1]) pn

-- | Reduce a network to a classification, by recursively reducing the leaves of the tree,
-- until only a root node is left
reduceNetwork :: PerceptronNetwork -> Classification
reduceNetwork tree
    | (length $ flatten tree) == 1 = head $ head $ flatten tree
    | otherwise = reduceNetwork $ reduceLeaves tree

-- | Reduce the leaves of the network tree.
-- A single leaf 'reduces' to itself
--
-- A tree with 1 child, which is a leaf, assumes the child node contains a biased input
-- vector and prunes it, returning a leaf with the classification according to the hyperplane at
-- the current node
--
-- A tree with multiple branches, all of which are leaves, is a combinator. It constructs a vector
-- out of the values of its children, adds a unit bias, and prunes, returning a leaf which represents
-- the combined classification
--
-- All other cases simply map over their leaves
reduceLeaves :: PerceptronNetwork -> PerceptronNetwork
reduceLeaves tree
    | leaf tree = tree -- a leaf "reduces" to itself
    | (length $ subForest tree) == 1-- only a single leaf, assume it is "biased"
      = Node { rootLabel = [sign $ (rootLabel tree) <.> (rootLabel $ head $ subForest tree)]
             , subForest = []
        }
    | and $ map leaf $ subForest tree -- all branches are leaves: join into a vector and add unit bias
        = Node { rootLabel = [sign $ (rootLabel tree) <.> ((concat $ map rootLabel $ subForest tree) ++ [1.0])]
               , subForest = []
               }
    | otherwise = Node { rootLabel = rootLabel tree
                       , subForest = map reduceLeaves $ subForest tree
                       }

-- | Count the number of perceptrons in a 'Network'
countPerceptrons :: Network -> Int
countPerceptrons = length . flatten . perceptronNetwork
